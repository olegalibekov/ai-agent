import os
import json
import asyncio
from dotenv import load_dotenv

from openai import OpenAI
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise RuntimeError("OPENAI_API_KEY is not set")

client = OpenAI(api_key=api_key)

SYSTEM_PROMPT = """
–¢—ã –∞–≥–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –≤—ã–∑—ã–≤–∞—Ç—å MCP-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã.
–í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–π, –º–æ–∂–Ω–æ –ª–∏ —Ä–µ—à–∏—Ç—å –∑–∞–¥–∞—á—É —á–µ—Ä–µ–∑ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã.
–ù–µ –¥–∞–≤–∞–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç, –ø–æ–∫–∞ –≤—Å—è —Ü–µ–ø–æ—á–∫–∞, –Ω—É–∂–Ω–∞—è –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏, –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞.
""".strip()


async def run_agent(user_query: str) -> None:
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π MCP-—Å–µ—Ä–≤–µ—Ä
    server_params = StdioServerParameters(
        command="python",
        args=["mcp_pipeline_server.py"],
    )

    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()

            # 1. –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ MCP-—Ç—É–ª–æ–≤
            tools_response = await session.list_tools()

            # 2. –ì–æ—Ç–æ–≤–∏–º tools –¥–ª—è Responses API
            openai_tools: list = []
            for t in tools_response.tools:
                openai_tools.append(
                    {
                        "type": "function",
                        "name": t.name,
                        "description": t.description or "",
                        "parameters": t.inputSchema or {
                            "type": "object",
                            "properties": {},
                        },
                    }
                )

            # 3. –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ Responses API
            # –í–∞–∂–Ω—ã–π –º–æ–º–µ–Ω—Ç: –∑–¥–µ—Å—å –ù–ï–¢ role="tool"
            initial_prompt = f"{SYSTEM_PROMPT}\n\n–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n{user_query}"

            response = client.responses.create(
                model="gpt-4.1-mini",
                input=initial_prompt,
                tools=openai_tools,
            )

            while True:
                tool_outputs: list = []

                # 4. Output: –∏—â–µ–º function_call
                for item in response.output:
                    if item.type == "function_call":
                        tool_name = item.name
                        raw_args = item.arguments or "{}"

                        try:
                            args = json.loads(raw_args)
                        except json.JSONDecodeError:
                            args = {}
                            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å arguments: {raw_args}")

                        print(f"\nüõ†  –í—ã–∑–æ–≤ MCP-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞: {tool_name}({args})")

                        # –í—ã–∑–æ–≤ MCP-—Ç—É–ª–∞ –ø–æ –∏–º–µ–Ω–∏
                        mcp_result = await session.call_tool(tool_name, args)

                        # –î–æ—Å—Ç–∞—ë–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ MCP
                        result_text_parts: list[str] = []
                        for part in mcp_result.content:
                            # FastMCP/—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —á–∞—Å—Ç–∏ –æ–±—ã—á–Ω–æ –∏–º–µ—é—Ç .text
                            txt = getattr(part, "text", None)
                            if txt:
                                result_text_parts.append(txt)
                            else:
                                result_text_parts.append(str(part))

                        result_text = "\n".join(result_text_parts).strip()

                        # 5. –î–æ–±–∞–≤–ª—è–µ–º function_call_output –¥–ª—è Responses API
                        tool_outputs.append(
                            {
                                "type": "function_call_output",
                                "call_id": item.call_id,
                                "output": result_text,
                            }
                        )

                # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ù–ï –∑–∞–ø—Ä–æ—Å–∏–ª–∞ –Ω–æ–≤—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ ‚Äî —ç—Ç–æ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
                if not tool_outputs:
                    # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ assistant-—Å–æ–æ–±—â–µ–Ω–∏–µ
                    final_text_parts: list[str] = []
                    for item in response.output:
                        if item.type == "message" and getattr(item, "role", None) == "assistant":
                            # item.content ‚Äî —Å–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤, —É –∫–∞–∂–¥–æ–≥–æ –µ—Å—Ç—å .text
                            for block in item.content:
                                txt = getattr(block, "text", None)
                                if txt:
                                    final_text_parts.append(txt)

                    final_answer = "\n".join(final_text_parts) if final_text_parts else "<empty answer>"

                    print("\n=== FINAL ANSWER ===\n")
                    print(final_answer)
                    break

                # 6. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—ã–≤–æ–¥—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –æ–±—Ä–∞—Ç–Ω–æ –≤ –º–æ–¥–µ–ª—å
                # previous_response_id —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Å—ë —Å–æ—Å—Ç–æ—è–Ω–∏–µ (–≤–∫–ª—é—á–∞—è reasoning –∏ —Ç.–¥.)
                response = client.responses.create(
                    model="gpt-4.1-mini",
                    tools=openai_tools,
                    input=tool_outputs,
                    previous_response_id=response.id,
                )


if __name__ == "__main__":
    asyncio.run(
        run_agent(
            "–ù–∞–π–¥–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø—Ä–æ ML, —Å–¥–µ–ª–∞–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é –∏ —Å–æ—Ö—Ä–∞–Ω–∏ –≤ —Ñ–∞–π–ª result.txt"
        )
    )
