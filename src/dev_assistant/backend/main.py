"""
AI Assistant –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ —Å RAG –∏ MCP –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π
"""
import os
from pathlib import Path
from typing import List, Dict, Optional

import anthropic
import faiss
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sentence_transformers import SentenceTransformer

load_dotenv()

app = FastAPI(title="Dev Assistant API")

# CORS –¥–ª—è Flutter web
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
embedding_model = None
faiss_index = None
documents = []
document_metadata = []


class Message(BaseModel):
    content: str
    project_path: Optional[str] = None


class IndexRequest(BaseModel):
    project_path: str


class RAGSystem:
    """–°–∏—Å—Ç–µ–º–∞ RAG –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞"""

    def __init__(self):
        print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã...")
        self.model = SentenceTransformer('all-mpnet-base-v2')
        self.index = None
        self.documents = []
        self.metadata = []

    def load_documents(self, project_path: str) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞"""
        docs = []
        project_path = Path(project_path)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º README
        readme_path = project_path / "README.md"
        if readme_path.exists():
            content = readme_path.read_text(encoding='utf-8')
            docs.append({
                'content': content,
                'source': 'README.md',
                'type': 'markdown'
            })
            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω README.md")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –∏–∑ docs/
        docs_dir = project_path / "docs"
        if docs_dir.exists():
            for file in docs_dir.rglob("*.md"):
                try:
                    content = file.read_text(encoding='utf-8')
                    relative_path = file.relative_to(project_path)
                    docs.append({
                        'content': content,
                        'source': str(relative_path),
                        'type': 'markdown'
                    })
                    print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω {relative_path}")
                except Exception as e:
                    print(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file}: {e}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º pubspec.yaml
        pubspec_path = project_path / "pubspec.yaml"
        if pubspec_path.exists():
            content = pubspec_path.read_text(encoding='utf-8')
            docs.append({
                'content': content,
                'source': 'pubspec.yaml',
                'type': 'yaml'
            })
            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω pubspec.yaml")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ .dart —Ñ–∞–π–ª—ã –∏–∑ lib/
        lib_dir = project_path / "lib"
        if lib_dir.exists():
            for file in lib_dir.rglob("*.dart"):
                try:
                    content = file.read_text(encoding='utf-8')
                    relative_path = file.relative_to(project_path)
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
                    if len(content) > 10000:
                        content = content[:10000] + "\n... (truncated)"
                    docs.append({
                        'content': content,
                        'source': str(relative_path),
                        'type': 'dart'
                    })
                    print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω {relative_path}")
                except Exception as e:
                    print(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file}: {e}")

        return docs

    def chunk_text(self, text: str, chunk_size: int = 500) -> List[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏"""
        words = text.split()
        chunks = []
        current_chunk = []
        current_size = 0

        for word in words:
            current_chunk.append(word)
            current_size += len(word) + 1

            if current_size >= chunk_size:
                chunks.append(' '.join(current_chunk))
                current_chunk = []
                current_size = 0

        if current_chunk:
            chunks.append(' '.join(current_chunk))

        return chunks

    def index_documents(self, docs: List[Dict]):
        """–ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ FAISS"""
        print(f"\n–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è {len(docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")

        all_chunks = []
        chunk_metadata = []

        for doc in docs:
            chunks = self.chunk_text(doc['content'])
            for i, chunk in enumerate(chunks):
                all_chunks.append(chunk)
                chunk_metadata.append({
                    'source': doc['source'],
                    'type': doc['type'],
                    'chunk_id': i,
                    'total_chunks': len(chunks)
                })

        print(f"–°–æ–∑–¥–∞–Ω–æ {len(all_chunks)} —á–∞–Ω–∫–æ–≤")

        # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        print("–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
        embeddings = self.model.encode(all_chunks, show_progress_bar=True)

        # –°–æ–∑–¥–∞–µ–º FAISS –∏–Ω–¥–µ–∫—Å
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatL2(dimension)
        self.index.add(embeddings.astype('float32'))

        self.documents = all_chunks
        self.metadata = chunk_metadata

        print(f"‚úì –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! {len(all_chunks)} —á–∞–Ω–∫–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ")

    def search(self, query: str, k: int = 3) -> List[Dict]:
        """–ò—â–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã"""
        if self.index is None or len(self.documents) == 0:
            return []

        query_embedding = self.model.encode([query])
        distances, indices = self.index.search(query_embedding.astype('float32'), k)

        results = []
        for i, idx in enumerate(indices[0]):
            if idx < len(self.documents):
                results.append({
                    'content': self.documents[idx],
                    'metadata': self.metadata[idx],
                    'distance': float(distances[0][i])
                })

        return results


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã
rag_system = RAGSystem()


@app.post("/index")
async def index_project(request: IndexRequest):
    """–ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –ø—Ä–æ–µ–∫—Ç –¥–ª—è RAG"""
    try:
        project_path = request.project_path
        if not os.path.exists(project_path):
            raise HTTPException(status_code=404, detail="–ü—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        docs = rag_system.load_documents(project_path)
        if not docs:
            raise HTTPException(status_code=400, detail="–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        rag_system.index_documents(docs)

        return {
            "status": "success",
            "message": f"–ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(docs)}",
            "documents": [d['source'] for d in docs]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/chat")
async def chat(message: Message):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–æ–º–∞–Ω–¥—ã /help"""
    try:
        user_message = message.content.strip()

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã /help
        if user_message.startswith("/help"):
            query = user_message.replace("/help", "").strip()

            if not query:
                return {
                    "response": """ü§ñ **Dev Assistant - –ö–æ–º–∞–Ω–¥—ã –ø–æ–º–æ—â–∏**

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `/help <–≤–æ–ø—Ä–æ—Å>` –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–µ–∫—Ç–µ.

**–ü—Ä–∏–º–µ—Ä—ã:**
- `/help —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞`
- `/help –∫–∞–∫ –¥–æ–±–∞–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å`
- `/help –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è main.dart`
- `/help –∫–∞–∫–∏–µ –µ—Å—Ç—å –≤–∏–¥–∂–µ—Ç—ã`
- `/help –ø—Ä–∞–≤–∏–ª–∞ —Å—Ç–∏–ª—è –∫–æ–¥–∞`

–Ø –∏—â—É –æ—Ç–≤–µ—Ç—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞—é —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∫–æ–¥–∞!"""
                }

            # –ü–æ–∏—Å–∫ –ø–æ RAG
            results = rag_system.search(query, k=3)

            if not results:
                return {
                    "response": "‚ùå –ò–Ω–¥–µ–∫—Å –ø—É—Å—Ç. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä—É–π—Ç–µ –ø—Ä–æ–µ–∫—Ç —á–µ—Ä–µ–∑ /index"
                }

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            context = "\n\n".join([
                f"üìÑ **{r['metadata']['source']}** (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {1 / (1 + r['distance']):.2f})\n```\n{r['content']}\n```"
                for r in results
            ])

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Claude –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞
            api_key = os.getenv("ANTHROPIC_API_KEY")
            if not api_key:
                return {
                    "response": f"‚ö†Ô∏è ANTHROPIC_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\n\n**–ù–∞–π–¥–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:**\n\n{context}"
                }

            client = anthropic.Anthropic(api_key=api_key)

            prompt = f"""–¢—ã - AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞ Flutter. –ò—Å–ø–æ–ª—å–∑—É–π –Ω–∞–π–¥–µ–Ω–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å.

**–í–æ–ø—Ä–æ—Å:** {query}

**–ù–∞–π–¥–µ–Ω–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:**
{context}

–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –∏ –ø–æ–Ω—è—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ, –ø–æ–∫–∞–∂–∏ –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞."""

            response = client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=1000,
                messages=[{"role": "user", "content": prompt}]
            )

            return {
                "response": response.content[0].text,
                "sources": [r['metadata']['source'] for r in results]
            }

        # –û–±—ã—á–Ω—ã–π —á–∞—Ç
        return {
            "response": "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É `/help <–≤–æ–ø—Ä–æ—Å>` –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–º–æ—â–∏ –ø–æ –ø—Ä–æ–µ–∫—Ç—É."
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/health")
async def health():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    return {
        "status": "ok",
        "indexed_documents": len(rag_system.documents),
        "model": "all-mpnet-base-v2"
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
