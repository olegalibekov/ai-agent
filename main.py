import os
import html
import logging
from collections import defaultdict, deque
from asyncio import Lock
from pathlib import Path

from dotenv import load_dotenv
from openai import AsyncOpenAI
from openai.types.responses import Response

from telegram import Update
from telegram.constants import ChatAction, ParseMode
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

# -------------------- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ --------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
load_dotenv(dotenv_path=Path(__file__).with_name(".env"))

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
SYSTEM_PROMPT = os.getenv("SYSTEM_PROMPT", "You are a helpful assistant.")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")  # –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –ø–æ–º–µ–Ω—è–π—Ç–µ

if not BOT_TOKEN or not OPENAI_API_KEY:
    raise RuntimeError("–£–∫–∞–∂–∏ BOT_TOKEN –∏ OPENAI_API_KEY –≤ .env")

client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# -------------------- –î–∏–∞–ª–æ–≥–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ --------------------
HISTORY_LEN = int(os.getenv("HISTORY_LEN", "10"))  # –≥–ª—É–±–∏–Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ —á–∞—Ç—É
history: dict[int, deque[str]] = defaultdict(lambda: deque(maxlen=HISTORY_LEN))
user_locks: dict[int, Lock] = {}


def make_model_input(chat_id: int, user_text: str) -> str:
    """
    –°–æ–±–∏—Ä–∞–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:
    - –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–ø–ª–∏–∫–∏ (user/assistant) –≤ –ø–ª–æ—Å–∫–æ–º –≤–∏–¥–µ
    - —Ç–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    –≠—Ç–æ –ø—Ä–æ—Å—Ç–æ–π –∏ —É—Å—Ç–æ–π—á–∏–≤—ã–π —Å–ø–æ—Å–æ–± –¥–∞–≤–∞—Ç—å –º–æ–¥–µ–ª–∏ –∏—Å—Ç–æ—Ä–∏—é –≤ Responses API.
    """
    lines = []
    for i, turn in enumerate(history[chat_id]):
        lines.append(turn)
    lines.append(f"User: {user_text}")
    return "\n".join(lines).strip()


def push_turn(chat_id: int, role: str, text: str) -> None:
    role = "User" if role == "user" else "Assistant"
    history[chat_id].append(f"{role}: {text}")


# -------------------- –•—ç–Ω–¥–ª–µ—Ä—ã --------------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    history[chat_id].clear()
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø —á–∞—Ç-–±–æ—Ç —Å ChatGPT ü§ñ\n"
        "–ù–∞–ø–∏—à–∏ –º–Ω–µ —á—Ç–æ-–Ω–∏–±—É–¥—å ‚Äî –æ—Ç–≤–µ—á—É –≤ —Ç–æ–º –∂–µ –¥–∏–∞–ª–æ–≥–µ.\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/reset ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç\n"
        "/help ‚Äî –ø–æ–¥—Å–∫–∞–∑–∫–∞"
    )


async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–Ø –ø–µ—Ä–µ–¥–∞—é —Ç–≤–æ–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ ChatGPT —á–µ—Ä–µ–∑ Responses API.\n"
        "–ú–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å —Å–∏—Å—Ç–µ–º–Ω—É—é —Ä–æ–ª—å —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é SYSTEM_PROMPT –≤ .env.\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/start ‚Äî –Ω–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ\n"
        "/reset ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç"
    )


async def reset(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    history[chat_id].clear()
    await update.message.reply_text("–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω üßπ")


async def chat(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    text = (update.message.text or "").strip()
    if not text:
        return

    if chat_id not in user_locks:
        user_locks[chat_id] = Lock()
    lock = user_locks[chat_id]
    if lock.locked():
        # –∑–∞—â–∏—â–∞–µ–º –æ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∏ –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–ø—Ä–∞–≤–∫–∞—Ö
        return

    async with lock:
        await context.bot.send_chat_action(chat_id, ChatAction.TYPING)
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –≤–≤–æ–¥ –¥–ª—è –º–æ–¥–µ–ª–∏
            push_turn(chat_id, "user", text)
            model_input = make_model_input(chat_id, text)

            # –í—ã–∑–æ–≤ Responses API
            # –í–∞–∂–Ω–æ: –Ω–µ –∑–∞–¥–∞—ë–º temperature (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª–∏ –ø—Ä–∏–Ω–∏–º–∞—é—Ç —Ç–æ–ª—å–∫–æ –¥–µ—Ñ–æ–ª—Ç)
            resp: Response = await client.responses.create(
                model=OPENAI_MODEL,
                instructions=SYSTEM_PROMPT,  # ‚Üê —Å–∏—Å—Ç–µ–º–Ω–∞—è —Ä–æ–ª—å
                input=model_input,  # ‚Üê —Å—Ç—Ä–æ–∫–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º/—Å–æ–æ–±—â–µ–Ω–∏–µ–º
                max_output_tokens=700,
            )
            answer = (resp.output_text or "").strip()

            if not answer:
                answer = "ü§î –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π —Å–ø—Ä–æ—Å–∏—Ç—å –∏–Ω–∞—á–µ."

            push_turn(chat_id, "assistant", answer)
            await update.message.reply_text(answer, parse_mode=ParseMode.HTML)

        except Exception as e:
            logging.exception(e)
            await update.message.reply_text("–£–ø—Å, —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ –ø–æ–∑–∂–µ üôè")


# -------------------- –ó–∞–ø—É—Å–∫ --------------------
def main():
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("reset", reset))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, chat))

    logging.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")
    app.run_polling()


if __name__ == "__main__":
    main()
