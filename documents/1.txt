Заметки по разбиению текста на чанки

При построении индекса для RAG особо важен этап разбиения текста на чанки (chunking). От качества чанкинга напрямую зависит качество поиска и точность ответов.

Основные подходы к чанкингу

Фиксированный размер окна

Пример: 512 токенов с пересечением 64–128 токенов.

Плюсы: простота реализации.

Минусы: можно порезать важный абзац пополам, потеряв локальный контекст.

Семантический чанкинг

Используются эмбеддинги и алгоритмы кластеризации или сегментации текста.

Идея: разделять текст там, где сильно меняется семантика.

Плюсы: потенциально лучшее качество.

Минусы: сложность и вычислительная стоимость.

Практические рекомендации

Для начала можно использовать фиксированные чанки по 300–500 слов с небольшим overlap.

Для технической документации и README хороши структурные чанки по заголовкам – они легко восстанавливаются.

Важно сохранять метаданные:

название документа,

путь до файла,

раздел (например, "Регламенты", "Инструкции по отпуску", "FAQ по авторизации").

Типичные ошибки

Слишком большие чанки → векторный поиск возвращает много лишнего текста.

Слишком маленькие чанки → модель теряет контекст, ответы становятся «обрывочными».

Отсутствие overlap → важные фразы оказываются на границе чанков и теряются.